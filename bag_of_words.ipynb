{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8847ac-25b5-4aed-9e9b-a64ff6cbf001",
   "metadata": {},
   "source": [
    "# Text Classification Bag of Words\n",
    "\n",
    "Outline\n",
    "- Download and explore the data\n",
    "- Apply text processing techniques\n",
    "- Implement bag of words model\n",
    "- Train ML models for text classification\n",
    "- Make predictions and publish to kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c0ef1",
   "metadata": {},
   "source": [
    "## Download and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2068af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1795a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea50e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c quora-insincere-questions-classification -f train.csv -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7202409",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = 'data/train.csv.zip'\n",
    "test_fname = 'data/test.csv.zip'\n",
    "sample_fname = 'data/sample_submission.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3de01e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acae4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(train_fname)\n",
    "raw_df\n",
    "# insincere questions has target as 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sincere_df = raw_df[raw_df['target'] == 0]\n",
    "insincere_df = raw_df[raw_df['target'] == 1]\n",
    "insincere_df['question_text'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['target'].value_counts(normalize=True).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40231c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_fname)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(sample_fname)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0beae560",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf15448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create working sample of data\n",
    "sample_df = raw_df.sample(SAMPLE_SIZE, random_state=42)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7987748",
   "metadata": {},
   "source": [
    "## Apply text processing techniques\n",
    "Outline:\n",
    "1. Undertsand the Bag of Words model\n",
    "2. Tokenisation\n",
    "3. Stop word removal\n",
    "4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d288ee04",
   "metadata": {},
   "source": [
    "#### Bag of Words Intuition\n",
    "1. Create list of all the words across all the text documents\n",
    "2. Convert each document into a vector containing the counts of each word\n",
    "\n",
    "Limitations:\n",
    "1. There may be too many words\n",
    "2. Some words may occur too frequently\n",
    "3. Some words may occur very rarely or only once\n",
    "4. Single word can have many forms (eg: go, gone, going or bird, birds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410405b7",
   "metadata": {},
   "source": [
    "#### Tokenisation\n",
    "Splitting the document into  words and separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99529dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = sincere_df['question_text'].values[1]\n",
    "q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = raw_df[raw_df['target'] == 1].question_text.values[0]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2650a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_tok = word_tokenize(q0)\n",
    "q0_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd34ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tok = word_tokenize(q1)\n",
    "q1_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dffe66",
   "metadata": {},
   "source": [
    "#### Stop Word Removal\n",
    "\n",
    "Removing commonly occurring words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "english_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc646d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in english_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_stop = remove_stopwords(q0_tok)\n",
    "q0_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2725e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_stop = remove_stopwords(q1_tok)\n",
    "q1_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03d0b1",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "Moving words to the root word eg: go, gone, going -> go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "153efac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_stem = [stemmer.stem(word) for word in q0_stop]\n",
    "q0_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d060cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_stem = [stemmer.stem(word) for word in q1_stop]\n",
    "q1_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b87a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use Lemmatization instead of Stemmer which gives meaningful words but it is not generally used as it looks for dictionary words and\n",
    "# can result in slowness "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb271c",
   "metadata": {},
   "source": [
    "## Implement bag of words model\n",
    "\n",
    "Outline:\n",
    "- Create a vocabulary using Count Vectorizer\n",
    "- Transform text to Vectors using Count Vectorizer\n",
    "- Configure Text Preprocessing in Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba5fed",
   "metadata": {},
   "source": [
    "#### Create a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = sample_df[:5]\n",
    "small_df['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d407a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ef560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vect.fit(small_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a51dc3",
   "metadata": {},
   "source": [
    "#### Transform documents to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = small_vect.transform(small_df['question_text']).toarray()\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7064eb",
   "metadata": {},
   "source": [
    "#### Configure Count Vectorizer Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fbb2e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [stemmer.stem(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f54df331",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, tokenizer=tokenize, stop_words=english_stopwords, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66acf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer.fit(sample_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "256b0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = vectorizer.transform(sample_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ee971",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4a96172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = vectorizer.transform(test_df['question_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d179f6",
   "metadata": {},
   "source": [
    "## Train ML models for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d2db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda6a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153e2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690094e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2aa080b",
   "metadata": {},
   "source": [
    "## Make predictions and publish to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f68df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52928478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71b0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
